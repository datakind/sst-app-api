resources:
  jobs:
    pdp_inference_pipeline:
      name: pdp_inference_pipeline
      job_clusters:
        - job_cluster_key: pdp-inference-pipeline-cluster
          new_cluster:
            spark_version: 16.1.x-cpu-ml-scala2.12
            spark_conf:
              "spark.master": "local[*, 4]"
              "spark.databricks.cluster.profile": "singleNode"
            gcp_attributes:
              google_service_account: pedro-pdp-inference-pipeline@dev-sst-02.iam.gserviceaccount.com
              zone_id: HA
              availability: ON_DEMAND_GCP
            data_security_mode: SINGLE_USER
            enable_elastic_disk: true
            runtime_engine: STANDARD
            node_type_id: n2-highmem-4
            custom_tags:
              "ResourceClass": "SingleNode"
              "x-databricks-nextgen-cluster": "true"
      tasks:
        - task_key: Need_synthetic_data
          condition_task:
            left: '{{job.parameters.synthetic_needed}}'
            op: EQUAL_TO
            right: True
          email_notifications: {}
          run_if: ALL_SUCCESS
        - task_key: generate_synthetic_data
          depends_on:
            - outcome: "true"
              task_key: Need_synthetic_data
          job_cluster_key: pdp-inference-pipeline-cluster
          email_notifications: {}
          libraries:
            - pypi:
                package: faker
            - pypi:
                package: pandera
            - pypi:
                package: git+https://github.com/datakind/student-success-tool.git@develop
          notebook_task:
            base_parameters:
              avg_num_courses_per_student: "5"
              normalize_col_names: ""
              num_students: "300"
              save_dir: ""
              seed: ""
            notebook_path: ../src/synthetic_data_generation_pipeline_task.py
            source: WORKSPACE
          run_if: ALL_SUCCESS
        - task_key: data_ingestion
          depends_on:
            - outcome: "false"
              task_key: Need_synthetic_data
            - task_key: generate_synthetic_data
          job_cluster_key: pdp-inference-pipeline-cluster
          email_notifications: {}
          libraries:
            - pypi:
                package: faker
            - pypi:
                package: pandera
            - pypi:
                package: git+https://github.com/datakind/student-success-tool.git@develop
          notebook_task:
            notebook_path: ../src/data_ingestion_pipeline_task.py
            source: WORKSPACE
          run_if: AT_LEAST_ONE_SUCCESS
        - task_key: data_processing
          depends_on:
            - task_key: data_ingestion
          job_cluster_key: pdp-inference-pipeline-cluster
          email_notifications: {}
          libraries:
            - pypi:
                package: faker
            - pypi:
                package: pandera
            - pypi:
                package: git+https://github.com/datakind/student-success-tool.git@develop
          notebook_task:
            notebook_path: ../src/data_processing_pipeline_task.py
            source: WORKSPACE
          run_if: ALL_SUCCESS
        - task_key: data_validation
          depends_on:
            - task_key: data_processing
          job_cluster_key: pdp-inference-pipeline-cluster
          email_notifications: {}
          notebook_task:
            notebook_path: ../src/data_validation_pipeline_task.py
            source: WORKSPACE
          run_if: ALL_SUCCESS
        - task_key: inference
          depends_on:
            - task_key: data_validation
          job_cluster_key: pdp-inference-pipeline-cluster
          email_notifications:
            on_failure:
              - pedro.melendez@datakind.org
            on_start:
              - pedro.melendez@datakind.org
            on_success:
              - pedro.melendez@datakind.org
          libraries:
            - pypi:
                package: faker
            - pypi:
                package: pandera
            - pypi:
                package: git+https://github.com/datakind/student-success-tool.git@develop
          notebook_task:
            notebook_path: ../src/model_inference_pipeline_task.py
            source: WORKSPACE
          run_if: ALL_SUCCESS
      parameters:
        - name: cohort_file_name
          default: standard_pdp_institution_sample_STUDENT_SEMESTER_AR_DEIDENTIFIED.csv
        - name: course_file_name
          default: standard_pdp_institution_sample_COURSE_LEVEL_AR_DEID.csv
        - name: DB_workspace
          default: dev_sst_02
        - name: institution_id
          default: standard_pdp_institution
        - name: model_name
          default: latest_enrollment_model
        - name: model_type
          default: sklearn
        - name: sst_job_id
          default: job_id_{{job.run_id}}
        - name: synthetic_needed
          default: False
      email_notifications: {}
      max_concurrent_runs: 2
      queue:
        enabled: true
      webhook_notifications: {}
