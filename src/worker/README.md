# REST API for SST peripheral jobs/actions.

This job has no access to the databases used by the SST and should interact with the backend API as if it's another API caller.

## See Swagger UI for self-documentation of all currently available API endpoints

Go to `<env>-sst.datakind.org/worker/api/v1/docs`: e.g. https://dev-sst.datakind.org/worker/api/v1/docs

Note that dev and staging links are all behind a GCP Identity-Aware Proxy.

## Authentication

Authentication of this program is via Username/Password. There is a single username/password combination that will authenticate to this program and its set in the env var file as the variables `USERNAME` and `PASSWORD`. There's no user table or api key situation as this is a worker job with limited functionality. And it is supposed to have a limited set of users (a subset of Datakinders -- probably only one or two people).

This username/password combination can be used to generate a token. Which can then be used for the rest of the endpoints. This is handled automatically by FastAPI's basic auth flow.

### Authenticate via the Swagger UI

0. Get the username/password. In the local environment, these are the values set in your .env file. In the dev environment, navigate to GCP's secret manager control pane and look for the `<env>-worker-env-file` and find the USERNAME/PASSWORD variables.
1. Hit the authorize button on the top right, enter username/password in the OAuth2PasswordBearer form.
2. You are authenticated! You can execute the other endpoints from the swagger UI directly. You can modify the request body then hit execute and see the results.

## GCP Storage Access

The worker does need direct access to GCP storage. It accesses the <env>_sftp_ingestion bucket (and should create it for a given environment if it does not already exist) which is where it first pulls the SFTP ingested data from.

## Testing

Unit test files are named `<file_under_test>_test.py` to correspond with the files they are testing. Unit tests only test behavior introduced by logic written in those files and do not test any integration with other systems. To respect test isolation, we have the following levels of testing:

1. Unit tests where all other systems are mocked out (e.g. GCP storage etc.)
2. Dev environment with fake data to test integration on real systems, as all integration points are connected to the real endpoints in GCP etc.
3. Staging environment with real data (potentially sampled if your datasets are large) to test real data flowing through the full end to end setup of a real system that mimics prod.
4. Prod environment with real data on real systems.

That means for functions that are mainly doing integration pieces, we do not have unit tests for them, as we assume external systems work and mocking and testing these integration points would be near-useless. These can be tested at level 2 in the dev environment, which is setup for just this purpose.

This also means, it's not recommended for the local environment to connect to the dev environment. The four environments, `local`, `dev`, `staging`, `prod`, should also be isolated from each other.

While working in the local environment, it's recommended you mock out/stub out the calls to external systems. If you don't want to do that feel free to look into official documentation on how to auth to GCS (especially to bypass the Identity-Aware Proxy) from your local environment.

### Comment on Deployment

* Dev environment: gets deployed upon any new commit to b/develop.
* Staging environment: requires manual Cloud Build Trigger Run initiated by a human to pick up the most recent changes from b/develop.
* Prod environment: requires manual Cloud Build Trigger Run initiated by a human to pick up the most recent changes from b/develop.

For more information on deployment, see the Terraform setup and the GCP setup in the GCP console.

## Package Management

Package management is done via [uv](https://docs.astral.sh/uv/). When adding a new package, add it according to the uv documents and keep the `uv.lock` and `pyproject.toml` files up to date.

## Local Environment Setup

Enter into the root directory of the repo.

1. Copy the `./src/worker/.env.example` file to `./src/worker/.env`. Populate any needed fields.
1. `python3 -m venv .venv`
1. `source .venv/bin/activate`
1. `pip install uv`
1. `uv sync --all-extras --dev`

You're now in your virtual env with all your dependencies added.

For all of the following, the steps above are pre-requisites and you should be in the root folder of `sst-app-api/`.

### Spin up the app locally:

1. `export ENV_FILE_PATH=<full_path_to_your_worker_.env_file>` 
1. `fastapi dev src/worker/main.py --port 8000`
1. Go to `http://127.0.0.1:8000/worker/api/v1/docs`
1. Hit the `Authorize` button on the top right and enter the username/password.
1. Directly use the swagger UI or curl if you want.

For convenience: the .env.example username/password combo for the local env are:
* username: `tester-user`
* password: `tester-pw`

### Before committing, run the formatter and run the unit tests

1. Formatter: `black src/worker/.`
1. Unit tests: `coverage run -m pytest  -v -s ./src/worker/`

#### Optionally run pylint

`uv run pylint './src/worker/*' --errors-only` for only errors.

Non-error Pylint is very opinionated, and **SOMETIMES WRONG**. For example, there exist warnings to switch `== NONE` to `is None` for SQL query where clauses. THIS WILL CAUSE THE SQL QUERY TO NOT WORK -- (it appears to be due to how SqlAlchemy understands the clauses). So be careful when following the recommendations from pylint. While the worker doesn't have database actions, there may be other such cases.

## Environment Variables

For the deployed instances (dev, staging, prod) database related environment variables are set in the [terraform templates](../../terraform/modules/service/main.tf#L39), 
but most are set per project in [Cloud Secret Manager](https://console.cloud.google.com/security/secret-manager/secret/dev-worker-env-file/versions?project=dev-sst-02). To update the environment
variables in secret manager, create a new version from the UI, copying the previous values with
your changes.

## Other notes

The .env processing file is config.py -- make sure any new environment variables get added to this file so that the program will ensure its required on start up time and so that you can access it in other files using the config.py's maps.

For the bearer token, it appears FastAPI likes the bearer token to be structured like so: `Bearer <token_value>` as the field set in the authorization header.

## Local VSCode Debugging

From the Run & Debug panel (‚áß‚åòD on üçé) you can run the [debug launch config](../../.vscode/launch.json) for the webapp or worker modules. This will allow you to set breakpoints within the source code while the applications are running.

